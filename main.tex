\documentclass[11pt]{article}

% Language setting
\usepackage[turkish]{babel}
\usepackage{pythonhighlight}

\usepackage[a4paper,top=2cm,bottom=2cm,left=2cm,right=2cm,marginparwidth=2cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{verbatim}
\usepackage{fancyhdr} % for header and footer
\usepackage{titlesec}
\usepackage{parskip}

\setlength{\parindent}{0pt}

\titleformat{\subsection}[runin]{\bfseries}{\thesubsection}{1em}{}

\pagestyle{fancy} % activate the custom header/footer

% define the header/footer contents
\lhead{\small{23BLM-4014 Yapay Sinir Ağları Ara Sınav Soru ve Cevap Kağıdı}}
\rhead{\small{Dr. Ulya Bayram}}
\lfoot{}
\rfoot{}

% remove header/footer on first page
\fancypagestyle{firstpage}{
  \lhead{}
  \rhead{}
  \lfoot{}
  \rfoot{\thepage}
}
 

\title{Çanakkale Onsekiz Mart Üniversitesi, Mühendislik Fakültesi, Bilgisayar Mühendisliği Akademik Dönem 2022-2023\\
Ders: BLM-4014 Yapay Sinir Ağları/Bahar Dönemi\\ 
ARA SINAV SORU VE CEVAP KAĞIDI\\
Dersi Veren Öğretim Elemanı: Dr. Öğretim Üyesi Ulya Bayram}
\author{%
\begin{minipage}{\textwidth}
\raggedright
Öğrenci Adı Soyadı: Akın Taştan\\ % Adınızı soyadınızı ve öğrenci numaranızı noktaların yerine yazın
Öğrenci No: 190401012
\end{minipage}%
}

\date{14 Nisan 2023}

\begin{document}
\maketitle

\vspace{-.5in}
\section*{Açıklamalar:}
\begin{itemize}
    \item Vizeyi çözüp, üzerinde aynı sorular, sizin cevaplar ve sonuçlar olan versiyonunu bu formatta PDF olarak, Teams üzerinden açtığım assignment kısmına yüklemeniz gerekiyor. Bu bahsi geçen PDF'i oluşturmak için LaTeX kullandıysanız, tex dosyasının da yer aldığı Github linkini de ödevin en başına (aşağı url olarak) eklerseniz bonus 5 Puan! (Tavsiye: Overleaf)
    \item Çözümlerde ya da çözümlerin kontrolünü yapmada internetten faydalanmak, ChatGPT gibi servisleri kullanmak serbest. Fakat, herkesin çözümü kendi emeğinden oluşmak zorunda. Çözümlerinizi, cevaplarınızı aşağıda belirttiğim tarih ve saate kadar kimseyle paylaşmayınız. 
    \item Kopyayı önlemek için Github repository'lerinizin hiçbirini \textbf{14 Nisan 2023, saat 15:00'a kadar halka açık (public) yapmayınız!} (Assignment son yükleme saati 13:00 ama internet bağlantısı sorunları olabilir diye en fazla ekstra 2 saat daha vaktiniz var. \textbf{Fakat 13:00 - 15:00 arası yüklemelerden -5 puan!}
    \item Ek puan almak için sağlayacağınız tüm Github repository'lerini \textbf{en geç 15 Nisan 2023 15:00'da halka açık (public) yapmış olun linklerden puan alabilmek için!}
    \item \textbf{14 Nisan 2023, saat 15:00'dan sonra gönderilen vizeler değerlendirilmeye alınmayacak, vize notu olarak 0 (sıfır) verilecektir!} Son anda internet bağlantısı gibi sebeplerden sıfır almayı önlemek için assignment kısmından ara ara çözümlerinizi yükleyebilirsiniz yedekleme için. Verilen son tarih/saatte (14 Nisan 2023, saat 15:00) sistemdeki en son yüklü PDF geçerli olacak.
    \item Çözümlerin ve kodların size ait ve özgün olup olmadığını kontrol eden bir algoritma kullanılacaktır. Kopya çektiği belirlenen vizeler otomatikman 0 (sıfır) alacaktır. Bu nedenle çözümlerinizi ve kodlarınızı yukarıda sağladığım gün ve saatlere kadar kimseyle paylaşmayınız.
    \item Bu vizeden alınabilecek en yüksek not 100'dür. Toplam aldığınız puan 100'ü geçerse, aldığınız not 100'e sabitlenecektir.
    \item LaTeX kullanarak PDF oluşturanlar öz geçmişlerine LaTeX bildiklerini de eklemeyi unutmasınlar :)
    \item Bu vizedeki soruların çözümleri ve tex dosyası için istediğiniz kadar sayıda Github repository'si oluşturabilirsiniz. Sadece yukarıda belirttiğim tarihlerde (14 Nisan 2023 saat 15:00 ile 15 Nisan 2023 saat 15:00 arasında) public yapmayı/halka açmayı ve Github profilinizi de öz geçmişinize eklemeyi unutmayın :)
    \item Bilgisayarınıza hiçbir program kurmadan, Overleaf, Google Colab, Kaggle gibi ortamlar üzerinden bu vizeyi tamamlamanız mümkün. İyi çalışmalar!!
\end{itemize}

(Ekstra 5 puan) \url{OdevinTexDosyasınınGithubLinkiniburayakoyun.com}

\newpage
\section{(Toplam 10 Puan) Hopfield Networks:}

\subsection{(2 Puan)} \textbf{ChatGPT’ye size Hopfield Network’ler ile ilgili detaylı bilgi vermesini isteyin. Sorduğunuz soruyu, ChatGPT'nin çıkartığı cevabı aşağı koyun. Bu cevapta anlamadığınız terimleri de ChatGPT’ye sorup, sorduğunuz soruları ve ChatGPT’nin verdiği cevapları da sırayla aşağı koyun.}

\textbf{Explain hopfield network in detail}

A Hopfield network is a type of artificial neural network that is used for pattern recognition and optimization problems. It was invented by John Hopfield in 1982.

The Hopfield network consists of a set of neurons that are connected to each other through a set of weights. The neurons can be either on or off, and they interact with each other by sending signals through the weights. The weights are adjusted based on the training data, which is used to store patterns in the network.

The network is trained by presenting it with a set of patterns. Each pattern is represented by a vector of binary values, where each element corresponds to the state of a neuron in the network. The weights of the network are adjusted to minimize an energy function, which is defined as the sum of the squared differences between the actual output of the network and the desired output (i.e., the input pattern).

Once the network is trained, it can be used to recognize new patterns. To recognize a pattern, the network is presented with an input vector, which may be noisy or incomplete. The network then iteratively updates the state of its neurons until it converges to a stable state, which corresponds to one of the stored patterns. The stable state is reached when the energy function is minimized, which means that the network has found a pattern that is close to the input.

Hopfield networks are often used for associative memory, which is the ability to retrieve a stored pattern from partial or noisy input. They can also be used for optimization problems, such as the traveling salesman problem, where the goal is to find the shortest possible route that visits a set of cities. In this case, the cities are represented as neurons, and the weights represent the distances between them. The network is then iteratively updated to find the optimal route.

Overall, the Hopfield network is a powerful tool for pattern recognition and optimization problems, and it has been used in a variety of applications, including image recognition, speech recognition, and combinatorial optimization.


\textbf{Explain Hopfield Neural Network architecture}

The Hopfield Neural Network (HNN) is a type of recurrent neural network with a single layer of binary threshold neurons. It is designed to perform pattern recognition and associative memory tasks. The architecture of a Hopfield Neural Network is relatively simple, and it consists of the following components:

Neurons: The Hopfield network has a set of neurons, which can be either on or off. Each neuron represents a binary element of the pattern to be stored or recognized.

Connections: The neurons are fully connected to each other, which means that each neuron is connected to every other neuron in the network. The connections between the neurons are symmetric, which means that the connection between neuron i and neuron j is the same as the connection between neuron j and neuron i.

Weights: The connections between the neurons are represented by a set of weights, which are symmetrically assigned to the connection between the two neurons. The weights are learned during the training phase and represent the strength of the connection between two neurons.

Thresholds: Each neuron has a threshold value, which determines whether the neuron is on or off. If the weighted sum of the inputs to the neuron is greater than the threshold value, the neuron is turned on, and if it is less than the threshold value, the neuron is turned off.

The operation of a Hopfield Neural Network can be described as follows:

Initialization: The network is initialized with a set of binary patterns that need to be stored or recognized.

Training: During the training phase, the weights of the connections between the neurons are adjusted to store the binary patterns. The weights are adjusted so that the energy of the network is minimized when it is in the state of storing the patterns.

Recognition: During the recognition phase, the network is presented with a partial or noisy version of one of the stored patterns. The network then iteratively updates the state of its neurons until it reaches a stable state, which corresponds to one of the stored patterns. The stable state is reached when the energy of the network is minimized.

The Hopfield Neural Network has several advantages, including its ability to recognize patterns even when they are partially occluded or corrupted by noise. However, it has some limitations, including its sensitivity to spurious patterns and its inability to handle large amounts of data. Nonetheless, the Hopfield Neural Network is still widely used in various fields, including image and speech recognition, optimization, and robotics.

\subsection{(8 Puan)} \textbf{ChatGPT’nin açıklamalarından ne anladığınızı buraya kendi kelimelerinizle özetleyin. Örneğin ``Hopfield Network nedir? Ne işe yarar? Neden bilmemiz gerekir bunu? Gerçek hayatta kullanılıyor mu?'' gibi. Anlamadığınız kısımlar varsa ve ChatGPT’nin açıklamaları yeterli gelmezse internet dahil farklı kaynaklardan araştırıp, bilgilerin doğruluğunu sorgulamakta serbestsiniz. Konuyu doğru anlayıp anlamamanız puana etki edecektir. Kullandığınız kaynakları da belirtin!}

Hopfield sinir ağı özellikle desen tanıma ve optimizasyon problemleri için kullanılan, bütün nöronların birbiriyle ilişkili olduğu ve tek bir katmandan oluşan bir sinir ağıdır. Mimarisine göre nöron, noronlar arası ilişkiler , ağırlıklar ve bir nöronun aktive edilip edilmeyeceğini belirten eşik değerleri içerir.

Ağ bir dizi model sunularak eğitildikten sonra yeni desenleri tanımak için kullanılabilir. Gürültülü veya eksik olabilen bir giriş vektörü ağa sunulur. Ağ daha sonra, saklanan modellerden birine karşılık gelen kararlı bir duruma yaklaşana kadar nöronlarının durumunu yinelemeli olarak günceller. Kararlı duruma, enerji fonksiyonu en aza indirildiğinde ulaşılır, bu da ağın girdiye yakın bir model bulduğu anlamına gelir.

Hopfield sinir ağı, veriler gürültülü olsa dahi ilgili desenleri tanıyabilmesi gibi bir avantajının yanı sıra büyük miktarda veriyi işleyememesi gibi dezavantajı da vardır. Görüntü ve konuşma tanıma, optimizasyon ve robotik dahil olmak üzere çeşitli alanlarda hala yaygın olarak kullanılmaktadır.

\textbf{Kaynak: ChatGPT}


\section{(Toplam 10 Puan) Boltzman Machine:}

\subsection{(2 Puan)} \textbf{ChatGPT’ye size Boltzman Machine ilgili detaylı bilgi vermesini isteyin. Sorduğunuz soruyu, ChatGPT'nin çıkartığı cevabı aşağı koyun. Bu cevapta anlamadığınız terimleri de ChatGPT’ye sorup, sorduğunuz soruları ve ChatGPT’nin verdiği cevapları da sırayla aşağı koyun.}

\textbf{What is Boltzman Machin? Please explain in detail.}

Boltzmann machines are a type of artificial neural network that are based on the principles of statistical mechanics and probability theory. They were first introduced by Geoffrey Hinton and Terry Sejnowski in the 1980s as a way to simulate the learning processes of the human brain.

The basic architecture of a Boltzmann machine consists of a set of nodes or units that are connected to each other in a network. Each node can be in one of two states: on or off. The connections between the nodes have weights that determine the strength of the connection. The nodes are organized into layers, with the input layer receiving input from the external environment and the output layer producing the final output of the network.

The main idea behind Boltzmann machines is to learn the underlying patterns and structure in a dataset by adjusting the weights of the connections between the nodes in the network. This is done by using a process called Gibbs sampling, which involves iteratively updating the states of the nodes in the network based on the current state of the network and the probabilities of transitioning to different states.

Boltzmann machines are particularly useful for unsupervised learning tasks, where the goal is to learn the structure of a dataset without the need for explicit labels or targets. They can be used for a variety of tasks, including image and speech recognition, natural language processing, and recommendation systems.

One of the main advantages of Boltzmann machines is their ability to handle complex, high-dimensional datasets that traditional machine learning algorithms may struggle with. However, training Boltzmann machines can be computationally expensive, and there are many different variations and extensions of the basic architecture that have been proposed to address these challenges.

In summary, a Boltzmann machine is an artificial neural network that is designed to learn the structure of a dataset through unsupervised learning using principles from statistical mechanics and probability theory. They are particularly useful for handling complex, high-dimensional datasets but can be computationally expensive to train.


\subsection{(8 Puan)} \textbf{ChatGPT’nin açıklamalarından ne anladığınızı buraya kendi kelimelerinizle özetleyin. Örneğin ``Boltzman Machine nedir? Ne işe yarar? Neden bilmemiz gerekir bunu? Gerçek hayatta kullanılıyor mu?'' gibi. Anlamadığınız kısımlar varsa ve ChatGPT’nin açıklamaları yeterli gelmezse internet dahil farklı kaynaklardan araştırıp, bilgilerin doğruluğunu sorgulamakta serbestsiniz. Konuyu doğru anlayıp anlamamanız puana etki edecektir. Kullandığınız kaynakları da belirtin!}

Boltzmann Machine, istatistiksel ve olasılık teorisi ilkelerine dayanan bir tür yapay sinir ağıdır. İnsan beyninin öğrenme süreçlerini simüle etmenin bir yolu olarak tanıtıldılar.

Bir Boltzmann makinesinin temel mimarisi, bir ağda birbirine bağlı bir dizi düğüm veya birimden oluşur. Boltzmann makinelerinin arkasındaki ana fikir, ağdaki düğümler arasındaki bağlantıların ağırlıklarını ayarlayarak bir veri kümesindeki temel kalıpları ve yapıyı öğrenmektir. Boltzmann makineleri, denetimsiz öğrenme görevleri için özellikle kullanışlıdır ve geleneksel makine öğrenimi algoritmalarının güçlük çekebileceği karmaşık, yüksek boyutlu veri kümelerini işleme becerisine sahiptir. Görüntü ve konuşma tanıma, doğal dil işleme ve öneri sistemleri dahil olmak üzere çeşitli görevler için kullanılabilirler.

\textbf{Kaynak: ChatGPT}

\section{(Toplam 10 Puan) Markov Assumption ve Markov Chain:}

\subsection{(2 Puan)} \textbf{ChatGPT’ye size Markov assumption ve Markov Chain ilgili detaylı bilgi vermesini isteyin. Sorduğunuz soruyu, ChatGPT'nin çıkartığı cevabı aşağı koyun. Bu cevapta anlamadığınız terimleri de ChatGPT’ye sorup, sorduğunuz soruları ve ChatGPT’nin verdiği cevapları da sırayla aşağı koyun.}

\textbf{Please provide detailed information about Markov assumption and Markov Chain}

The Markov assumption, also known as the Markov property or Markov assumption, is a fundamental concept in probability theory and statistics. It states that the future state of a stochastic process or system depends only on its current state, and not on its past states. In other words, the future is independent of the past given the present.

The Markov assumption is important in many fields, including physics, economics, and computer science, and is used in a variety of applications, such as speech recognition, machine translation, and image processing.

A Markov chain is a stochastic model that is used to describe a sequence of events or states, where the Markov assumption holds. It consists of a set of states and a set of probabilities that determine the likelihood of transitioning from one state to another. The probabilities of transitioning from one state to another are often represented in a transition matrix.

The transition matrix is a square matrix whose elements represent the probabilities of transitioning from one state to another. The rows of the matrix represent the current state, and the columns represent the next state. The elements of each row sum to one, since the probability of transitioning to any possible next state must be one.

Markov chains can be either discrete or continuous. In a discrete-time Markov chain, the state transitions occur at discrete time intervals. In a continuous-time Markov chain, the state transitions occur continuously over time.

The properties of a Markov chain can be analyzed using a variety of mathematical techniques, including probability theory and linear algebra. One important concept in the study of Markov chains is the stationary distribution, which is a probability distribution that remains constant over time, regardless of the starting state. The stationary distribution can be found by solving a set of linear equations known as the balance equations.

Markov chains are used in many applications, including modeling the behavior of physical systems, analyzing the dynamics of financial markets, and predicting the weather. They are also used in machine learning and data science, where they can be used to model complex systems and make predictions about future behavior based on past observations.

\subsection{(8 Puan)} \textbf{ChatGPT’nin açıklamalarından ne anladığınızı buraya kendi kelimelerinizle özetleyin. Örneğin ``Markov assumption ve Markov Chain nedir? Ne işe yarar? Neden bilmemiz gerekir bunu? Gerçek hayatta kullanılıyor mu?'' gibi. Anlamadığınız kısımlar varsa ve ChatGPT’nin açıklamaları yeterli gelmezse internet dahil farklı kaynaklardan araştırıp, bilgilerin doğruluğunu sorgulamakta serbestsiniz. Konuyu doğru anlayıp anlamamanız puana etki edecektir. Kullandığınız kaynakları da belirtin!}

Markov varsayımı, olasılık teorisi ve istatistikte temel bir kavramdır. Bir sürecin veya sistemin gelecekteki durumunun, geçmiş durumlarına değil, yalnızca mevcut durumuna bağlı olduğunu belirtir. 

Bir Markov zinciri, bir durumdan diğerine geçiş olasılığını belirleyen bir dizi durumdan ve bir dizi olasılıktan oluşur. Bir durumdan diğerine geçiş olasılıkları genellikle bir geçiş matrisinde temsil edilir. Geçiş matrisi, elemanları bir durumdan diğerine geçiş olasılıklarını temsil eden kare bir matristir. Matrisin satırları mevcut durumu, sütunlar ise bir sonraki durumu temsil eder. Olası bir sonraki duruma geçiş olasılığı bir olması gerektiğinden, her satırın öğelerinin toplamı birdir.

Markov varsayımı fizik, ekonomi ve bilgisayar bilimi dahil birçok alanda önemlidir ve konuşma tanıma, makine çevirisi ve görüntü işleme gibi çeşitli uygulamalarda kullanılır.

\textbf{Kaynak: ChatGPT}

\section{(Toplam 20 Puan) Feed Forward:}
 
\begin{itemize}
    \item Forward propagation için, input olarak şu X matrisini verin (tensöre çevirmeyi unutmayın):\\
    $X = \begin{bmatrix}
        1 & 2 & 3\\
        4 & 5 & 6
        \end{bmatrix}$
    Satırlar veriler (sample'lar), kolonlar öznitelikler (feature'lar).
    \item Bir adet hidden layer olsun ve içinde tanh aktivasyon fonksiyonu olsun
    \item Hidden layer'da 50 nöron olsun
    \item Bir adet output layer olsun, tek nöronu olsun ve içinde sigmoid aktivasyon fonksiyonu olsun
\end{itemize}

Tanh fonksiyonu:\\
$f(x) = \frac{exp(x) - exp(-x)}{exp(x) + exp(-x)}$
\vspace{.2in}

Sigmoid fonksiyonu:\\
$f(x) = \frac{1}{1 + exp(-x)}$

\vspace{.2in}
 \textbf{Pytorch kütüphanesi ile, ama kütüphanenin hazır aktivasyon fonksiyonlarını kullanmadan, formülünü verdiğim iki aktivasyon fonksiyonunun kodunu ikinci haftada yaptığımız gibi kendiniz yazarak bu yapay sinir ağını oluşturun ve aşağıdaki üç soruya cevap verin.}
 
\subsection{(10 Puan)} \textbf{Yukarıdaki yapay sinir ağını çalıştırmadan önce pytorch için Seed değerini 1 olarak set edin, kodu aşağıdaki kod bloğuna ve altına da sonucu yapıştırın:}

% Latex'de kod koyabilirsiniz python formatında. Aşağıdaki örnekleri silip içine kendi kodunuzu koyun
\begin{python}
import torch
import math

# Set seed value to 1
torch.manual_seed(1)

# Define activation functions
def tanh(x):
    numerator = (torch.exp(x) - torch.exp(-x))
    denominator = (torch.exp(x) + torch.exp(-x))
    return numerator / denominator

def sigmoid(x):
    return 1 / (1 + torch.exp(-x))

# Define the neural network
class NeuralNet(torch.nn.Module):
    def __init__(self):
        super(NeuralNet, self).__init__()
        self.fc1 = torch.nn.Linear(in_features=3, out_features=50)
        self.fc2 = torch.nn.Linear(in_features=50, out_features=1)

    def forward(self, x):
        x = tanh(self.fc1(x))
        x = sigmoid(self.fc2(x))
        return x

# Create an instance of the neural network
model = NeuralNet()

# Feed the matrix x to the model
x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)
output = model(x)

# Print the output
print(output)

\end{python}

tensor([[0.4892],
        [0.5566]])
\clearpage
\subsection{(5 Puan)} \textbf{Yukarıdaki yapay sinir ağını çalıştırmadan önce Seed değerini öğrenci numaranız olarak değiştirip, kodu aşağıdaki kod bloğuna ve altına da sonucu yapıştırın:}

\begin{python}
import torch
import math

# Set seed value to 190401012
torch.manual_seed(190401012)

# Define activation functions
def tanh(x):
    numerator = (torch.exp(x) - torch.exp(-x))
    denominator = (torch.exp(x) + torch.exp(-x))
    return numerator / denominator

def sigmoid(x):
    return 1 / (1 + torch.exp(-x))

# Define the neural network
class NeuralNet(torch.nn.Module):
    def __init__(self):
        super(NeuralNet, self).__init__()
        self.fc1 = torch.nn.Linear(in_features=3, out_features=50)
        self.fc2 = torch.nn.Linear(in_features=50, out_features=1)

    def forward(self, x):
        x = tanh(self.fc1(x))
        x = sigmoid(self.fc2(x))
        return x

# Create an instance of the neural network
model = NeuralNet()

# Feed the matrix x to the model
x = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)
output = model(x)

# Print the output
print(output)

\end{python}

tensor([[0.2913],
        [0.3076]])

\subsection{(5 Puan)} \textbf{Kodlarınızın ve sonuçlarınızın olduğu jupyter notebook'un Github repository'sindeki linkini aşağıdaki url kısmının içine yapıştırın. İlk sayfada belirttiğim gün ve saate kadar halka açık (public) olmasın:}
% size ait Github olmak zorunda, bu vize için ayrı bir github repository'si açıp notebook'u onun içine koyun. Kendine ait olmayıp da arkadaşının notebook'unun linkini paylaşanlar 0 alacak.

\url{https://github.com/akintastan/YapaySinirAglari/tree/master/YapaySinirAglari4}

\section{(Toplam 40 Puan) Multilayer Perceptron (MLP):} 
\textbf{Bu bölümdeki sorularda benim vize ile beraber paylaştığım Prensesi İyileştir (Cure The Princess) Veri Seti parçaları kullanılacak. Hikaye şöyle (soruyu çözmek için hikaye kısmını okumak zorunda değilsiniz):} 

``Bir zamanlar, çok uzaklarda bir ülkede, ağır bir hastalığa yakalanmış bir prenses yaşarmış. Ülkenin kralı ve kraliçesi onu iyileştirmek için ellerinden gelen her şeyi yapmışlar, ancak denedikleri hiçbir çare işe yaramamış.

Yerel bir grup köylü, herhangi bir hastalığı iyileştirmek için gücü olduğu söylenen bir dizi sihirli malzemeden bahsederek kral ve kraliçeye yaklaşmış. Ancak, köylüler kral ile kraliçeyi, bu malzemelerin etkilerinin patlayıcı olabileceği ve son zamanlarda yaşanan kuraklıklar nedeniyle bu malzemelerden sadece birkaçının herhangi bir zamanda bulunabileceği konusunda uyarmışlar. Ayrıca, sadece deneyimli bir simyacı bu özelliklere sahip patlayıcı ve az bulunan malzemelerin belirli bir kombinasyonunun prensesi iyileştireceğini belirleyebilecekmiş.

Kral ve kraliçe kızlarını kurtarmak için umutsuzlar, bu yüzden ülkedeki en iyi simyacıyı bulmak için yola çıkmışlar. Dağları tepeleri aşmışlar ve nihayet "Yapay Sinir Ağları Uzmanı" olarak bilinen yeni bir sihirli sanatın ustası olarak ün yapmış bir simyacı bulmuşlar.

Simyacı önce köylülerin iddialarını ve her bir malzemenin alınan miktarlarını, ayrıca iyileşmeye yol açıp açmadığını incelemiş. Simyacı biliyormuş ki bu prensesi iyileştirmek için tek bir şansı varmış ve bunu doğru yapmak zorundaymış. (Original source: \url{https://www.kaggle.com/datasets/unmoved/cure-the-princess})

(Buradan itibaren ChatGPT ve Dr. Ulya Bayram'a ait hikayenin devamı)

Simyacı, büyülü bileşenlerin farklı kombinasyonlarını analiz etmek ve denemek için günler harcamış. Sonunda birkaç denemenin ardından prensesi iyileştirecek çeşitli karışım kombinasyonları bulmuş ve bunları bir veri setinde toplamış. Daha sonra bu veri setini eğitim, validasyon ve test setleri olarak üç parçaya ayırmış ve bunun üzerinde bir yapay sinir ağı eğiterek kendi yöntemi ile prensesi iyileştirme ihtimalini hesaplamış ve ikna olunca kral ve kraliçeye haber vermiş. Heyecanlı ve umutlu olan kral ve kraliçe, simyacının prensese hazırladığı ilacı vermesine izin vermiş ve ilaç işe yaramış ve prenses hastalığından kurtulmuş.

Kral ve kraliçe, kızlarının hayatını kurtardığı için simyacıya krallıkta kalması ve çalışmalarına devam etmesi için büyük bir araştırma bütçesi ve çok sayıda GPU'su olan bir server vermiş. İyileşen prenses de kendisini iyileştiren yöntemleri öğrenmeye merak salıp, krallıktaki üniversitenin bilgisayar mühendisliği bölümüne girmiş ve mezun olur olmaz da simyacının yanında, onun araştırma grubunda çalışmaya başlamış. Uzun yıllar birlikte krallıktaki insanlara, hayvanlara ve doğaya faydalı olacak yazılımlar geliştirmişler, ve simyacı emekli olduğunda prenses hem araştırma grubunun hem de krallığın lideri olarak hayatına devam etmiş.

Prenses, kendisini iyileştiren veri setini de, gelecekte onların izinden gidecek bilgisayar mühendisi prensler ve prensesler başkalarına faydalı olabilecek yapay sinir ağları oluşturmayı öğrensinler diye halka açmış ve sınavlarda kullanılmasını salık vermiş.''

\textbf{İki hidden layer'lı bir Multilayer Perceptron (MLP) oluşturun beşinci ve altıncı haftalarda yaptığımız gibi. Hazır aktivasyon fonksiyonlarını kullanmak serbest. İlk hidden layer'da 100, ikinci hidden layer'da 50 nöron olsun. Hidden layer'larda ReLU, output layer'da sigmoid aktivasyonu olsun.}

\textbf{Output layer'da kaç nöron olacağını veri setinden bakıp bulacaksınız. Elbette bu veriye uygun Cross Entropy loss yöntemini uygulayacaksınız. Optimizasyon için Stochastic Gradient Descent yeterli. Epoch sayınızı ve learning rate'i validasyon seti üzerinde denemeler yaparak (loss'lara overfit var mı diye bakarak) kendiniz belirleyeceksiniz. Batch size'ı 16 seçebilirsiniz.}


\subsection{(10 Puan)} \textbf{Bu MLP'nin pytorch ile yazılmış class'ının kodunu aşağı kod bloğuna yapıştırın:}

\clearpage
\begin{python}
class MyNeuralNetwork(nn.Module):
    def __init__(self):
        super(MyNeuralNetwork, self).__init__()
        self.layer1 = nn.Linear(in_features=13, out_features=100) 
        self.layer2 = nn.Linear(in_features=100, out_features=50)
        self.layer3 = nn.Linear(in_features=50, out_features=2)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, x):
        x = self.relu(self.layer1(x))
        x = self.relu(self.layer2(x))
        x = self.sigmoid(self.layer3(x))
        return x

\end{python}

\subsection{(10 Puan)} \textbf{SEED=öğrenci numaranız set ettikten sonra altıncı haftada yazdığımız gibi training batch'lerinden eğitim loss'ları, validation batch'lerinden validasyon loss değerlerini hesaplayan kodu aşağıdaki kod bloğuna yapıştırın ve çıkan figürü de alta ekleyin.}

\begin{python}

# Set the seed value for random, numpy, and torch
seed_value = 190401012
random.seed(seed_value)
np.random.seed(seed_value)
torch.manual_seed(seed_value)


# Instantiate the model
model = MyNeuralNetwork()

# Define the loss function and optimizer
criterion = nn.BCELoss()
optimizer = optim.SGD(model.parameters(), lr=0.001)

#train the model
list_train_loss, list_val_loss = [], []
num_epochs = 100

for epoch in range(num_epochs):

    # Set the model to training mode
    model.train()

    # training loop
    train_loss = 0.0
    train_count = 0.0
    for inputs, labels in train_dataloader:

        # zero the parameter gradients
        optimizer.zero_grad()
        
        # Forward pass
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        
        # Backward pass and optimization
        loss.backward()
        optimizer.step()

        train_count += 1.0
        train_loss += loss.item()


    val_loss = 0.0
    with torch.no_grad():
        model.eval()
        for inputs, labels in val_dataloader:
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()


    # calculate metrics
    train_loss /= train_count
    val_loss /= len(val_dataloader)

    print("Epoch", epoch, "Training loss", train_loss,"Validation Loss :",val_loss)

    list_train_loss.append(train_loss)
    list_val_loss.append(val_loss)


sns.set_style("darkgrid")
plt.plot(list_train_loss, label="Training loss")
plt.plot(list_val_loss, label="Validation loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()

print('Finished Training')
\end{python}

% Figure aşağıda comment içindeki kısımdaki gibi eklenir.
%\begin{comment}
\begin{figure}[ht!]
    \centering
    %\includegraphics[width=0.75\textwidth]{val1.png}
    \includegraphics[width=5cm, height=4cm]{val1}
    \caption{Loss values obtained from training and validation data}
    \label{fig:loss table}
\end{figure}
%\end{comment}
\clearpage
\subsection{(10 Puan)} \textbf{SEED=öğrenci numaranız set ettikten sonra altıncı haftada ödev olarak verdiğim gibi earlystopping'deki en iyi modeli kullanarak, Prensesi İyileştir test setinden accuracy, F1, precision ve recall değerlerini hesaplayan kodu yazın ve sonucu da aşağı yapıştırın. \%80'den fazla başarı bekliyorum test setinden. Daha düşükse başarı oranınız, nerede hata yaptığınızı bulmaya çalışın. \%90'dan fazla başarı almak mümkün (ben denedim).}

\begin{python}
# Put the model in evaluation mode
model.eval()

# Initialize the variables for the metrics
tp = 0  # true positives
tn = 0  # true negatives
fp = 0  # false positives
fn = 0  # false negatives

# Iterate over the test data
for inputs, labels in test_dataloader:
    # Make predictions using the model
    outputs = model(inputs)
    predictions = torch.argmax(outputs, dim=1)

    # Compute the metrics
    tp += torch.sum((predictions == 1) & (labels[:, 1] == 1)).item()
    tn += torch.sum((predictions == 0) & (labels[:, 0] == 1)).item()
    fp += torch.sum((predictions == 1) & (labels[:, 0] == 1)).item()
    fn += torch.sum((predictions == 0) & (labels[:, 1] == 1)).item()

# Compute the metrics
accuracy = (tp + tn) / (tp + tn + fp + fn)
precision = tp / (tp + fp)
recall = tp / (tp + fn)
f1_score = 2 * precision * recall / (precision + recall)

print('Accuracy: {:.4f}'.format(accuracy))
print('Precision: {:.4f}'.format(precision))
print('Recall: {:.4f}'.format(recall))
print('F1 Score: {:.4f}'.format(f1_score))
\end{python}

Accuracy: 0.9016
Precision: 0.9503
Recall: 0.8464
F1 Score: 0.8953

\subsection{(5 Puan)} \textbf{Tüm kodların CPU'da çalışması ne kadar sürüyor hesaplayın. Sonra to device yöntemini kullanarak modeli ve verileri GPU'ya atıp kodu bir de böyle çalıştırın ve ne kadar sürdüğünü hesaplayın. Süreleri aşağıdaki tabloya koyun. GPU için Google Colab ya da Kaggle'ı kullanabilirsiniz, iki ortam da her hafta saatlerce GPU hakkı veriyor.}

\begin{table}[ht!]
    \centering
    \caption{CPU and GPU Runtime}
    \begin{tabular}{c|c}
        Ortam & Süre (saniye) \\\hline
        CPU & 46 \\
        GPU & 32\\
    \end{tabular}
    \label{tab:my_table}
\end{table}

\subsection{(3 Puan)} \textbf{Modelin eğitim setine overfit etmesi için elinizden geldiği kadar kodu gereken şekilde değiştirin, validasyon loss'unun açıkça yükselmeye başladığı, training ve validation loss'ları içeren figürü aşağı koyun ve overfit için yaptığınız değişiklikleri aşağı yazın. Overfit, tam bir çanak gibi olmalı ve yükselmeli. Ona göre parametrelerle oynayın.}

Hızlı öğrenmesi ve optimum noktayı kaçırması için learning rate'i arttırdım.

Nöron sayısını azaltarak ve epoch sayısını arttırarak verileri ezberlemesini istedim.

% Figür aşağı
%\begin{comment}
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.75\textwidth]{overfit.png}
    \caption{Overfitting}
    \label{fig:my_pic}
\end{figure}
%\end{comment}

\subsection{(2 Puan)} \textbf{Beşinci soruya ait tüm kodların ve cevapların olduğu jupyter notebook'un Github linkini aşağıdaki url'e koyun.}

\url{https://github.com/akintastan/YapaySinirAglari/tree/master/YapaySinirAglari5}

\section{(Toplam 10 Puan)} \textbf{Bir önceki sorudaki Prensesi İyileştir problemindeki yapay sinir ağınıza seçtiğiniz herhangi iki farklı regülarizasyon yöntemi ekleyin ve aşağıdaki soruları cevaplayın.} 

\subsection{(2 puan)} \textbf{Kodlarda regülarizasyon eklediğiniz kısımları aşağı koyun:} 

\begin{python}

class MyNeuralNetwork(nn.Module):
    def __init__(self):
        super(MyNeuralNetwork, self).__init__()
        self.layer1 = nn.Linear(in_features=13, out_features=100) 
        self.dropout1 = nn.Dropout(p=0.2)
        self.layer2 = nn.Linear(in_features=100, out_features=50)
        self.dropout2 = nn.Dropout(p=0.2)
        self.layer3 = nn.Linear(in_features=50, out_features=2)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()
        
    def forward(self, x):
        x = self.relu(self.layer1(x))
        x = self.dropout1(x)
        x = self.relu(self.layer2(x))
        x = self.dropout2(x)
        x = self.sigmoid(self.layer3(x))
        return x


# Define the loss function and optimizer
criterion = nn.BCELoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=0.01) # add weight_decay for L1 regularization


\end{python}

\subsection{(2 puan)} \textbf{Test setinden yeni accuracy, F1, precision ve recall değerlerini hesaplayıp aşağı koyun:}

Accuracy: 0.9249
Precision: 0.9201
Recall: 0.9297
F1 Score: 0.9249

\subsection{(5 puan)} \textbf{Regülarizasyon yöntemi seçimlerinizin sebeplerini ve sonuçlara etkisini yorumlayın:}



\subsection{(1 puan)} \textbf{Sonucun github linkini  aşağıya koyun:}

\url{https://github.com/akintastan/YapaySinirAglari/tree/master/YapaySinirAglari6}

\end{document}